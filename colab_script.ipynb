{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab_script.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNDI2EK4ZHYirrsKEHJqzDC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ultronify/cartpole-tf-dqn/blob/master/colab_script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwwngZlf_TgQ",
        "colab_type": "text"
      },
      "source": [
        "# Colab script for cartpole-tf repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYDw1-_eBeCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gitpython > /dev/null 2>&1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TioeaYG3_OXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import git\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJUPnRVbBa-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_branch = 'master'\n",
        "github_url = 'https://github.com/ultronify/cartpole-tf-dqn.git'\n",
        "repo_dir = os.path.join('./resource', 'repository')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGC98ENXBta0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if os.path.exists(repo_dir):\n",
        "  shutil.rmtree(repo_dir)\n",
        "repo = git.Repo.clone_from(github_url, repo_dir, branch=use_branch)\n",
        "if repo_dir not in sys.path:\n",
        "  sys.path.insert(0, repo_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojB_XlqYB0_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from train import train_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKQKvnMLB4C3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "75bbb18c-36b5-466c-eafe-f2f078bd87de"
      },
      "source": [
        "train_model(\n",
        "  verbose='progress',\n",
        "  visualizer_type='none',\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               640       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 9,026\n",
            "Trainable params: 9,026\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "Not enough sample, skipping...\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.2957\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Episode 53/20000(0.27%) finished with avg reward 7.4 w/ benchmark reward 13.8 and buffer volume 520\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.4986\n",
            "Episode 54/20000(0.27%) finished with avg reward 7.4 w/ benchmark reward 13.8 and buffer volume 528\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.6293\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Episode 55/20000(0.27%) finished with avg reward 7.6 w/ benchmark reward 13.8 and buffer volume 538\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.6641\n",
            "Episode 56/20000(0.28%) finished with avg reward 6.9 w/ benchmark reward 13.8 and buffer volume 546\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.5674\n",
            "Episode 57/20000(0.29%) finished with avg reward 7.0 w/ benchmark reward 13.8 and buffer volume 555\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.4258\n",
            "Episode 58/20000(0.29%) finished with avg reward 7.5 w/ benchmark reward 13.8 and buffer volume 565\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.3572\n",
            "Episode 59/20000(0.29%) finished with avg reward 7.4 w/ benchmark reward 13.8 and buffer volume 574\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2930\n",
            "Episode 60/20000(0.3%) finished with avg reward 7.5 w/ benchmark reward 13.8 and buffer volume 584\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.3002\n",
            "Episode 61/20000(0.3%) finished with avg reward 7.5 w/ benchmark reward 13.8 and buffer volume 594\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2323\n",
            "Episode 62/20000(0.31%) finished with avg reward 7.6 w/ benchmark reward 13.8 and buffer volume 604\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1961\n",
            "Episode 63/20000(0.32%) finished with avg reward 7.3 w/ benchmark reward 13.8 and buffer volume 613\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2450\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Episode 64/20000(0.32%) finished with avg reward 8.0 w/ benchmark reward 13.8 and buffer volume 622\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2771\n",
            "Episode 65/20000(0.33%) finished with avg reward 7.2 w/ benchmark reward 13.8 and buffer volume 631\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2358\n",
            "Episode 66/20000(0.33%) finished with avg reward 7.1 w/ benchmark reward 13.8 and buffer volume 641\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.2028\n",
            "Episode 67/20000(0.34%) finished with avg reward 7.4 w/ benchmark reward 13.8 and buffer volume 650\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2967\n",
            "Episode 68/20000(0.34%) finished with avg reward 7.3 w/ benchmark reward 13.8 and buffer volume 659\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2641\n",
            "Episode 69/20000(0.34%) finished with avg reward 7.3 w/ benchmark reward 13.8 and buffer volume 668\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2371\n",
            "Episode 70/20000(0.35%) finished with avg reward 7.3 w/ benchmark reward 13.8 and buffer volume 678\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0702\n",
            "Episode 71/20000(0.36%) finished with avg reward 7.3 w/ benchmark reward 13.8 and buffer volume 688\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2417\n",
            "Episode 72/20000(0.36%) finished with avg reward 7.5 w/ benchmark reward 13.8 and buffer volume 698\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2525\n",
            "Episode 73/20000(0.36%) finished with avg reward 7.1 w/ benchmark reward 13.8 and buffer volume 708\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2407\n",
            "Episode 74/20000(0.37%) finished with avg reward 7.8 w/ benchmark reward 13.8 and buffer volume 718\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1560\n",
            "Episode 75/20000(0.38%) finished with avg reward 7.5 w/ benchmark reward 13.8 and buffer volume 727\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1207\n",
            "Episode 76/20000(0.38%) finished with avg reward 7.5 w/ benchmark reward 13.8 and buffer volume 737\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2203\n",
            "Episode 77/20000(0.39%) finished with avg reward 7.4 w/ benchmark reward 13.8 and buffer volume 747\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1261\n",
            "Episode 78/20000(0.39%) finished with avg reward 7.5 w/ benchmark reward 13.8 and buffer volume 755\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1941\n",
            "Episode 79/20000(0.4%) finished with avg reward 7.2 w/ benchmark reward 13.8 and buffer volume 763\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2029\n",
            "Episode 80/20000(0.4%) finished with avg reward 7.3 w/ benchmark reward 13.8 and buffer volume 773\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0478\n",
            "Episode 81/20000(0.4%) finished with avg reward 7.4 w/ benchmark reward 13.8 and buffer volume 783\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2094\n",
            "Episode 82/20000(0.41%) finished with avg reward 7.1 w/ benchmark reward 13.8 and buffer volume 791\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1253\n",
            "Episode 83/20000(0.41%) finished with avg reward 7.5 w/ benchmark reward 13.8 and buffer volume 800\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1323\n",
            "Episode 84/20000(0.42%) finished with avg reward 7.2 w/ benchmark reward 13.8 and buffer volume 810\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1015\n",
            "Episode 85/20000(0.43%) finished with avg reward 7.4 w/ benchmark reward 13.8 and buffer volume 819\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0367\n",
            "Episode 86/20000(0.43%) finished with avg reward 7.3 w/ benchmark reward 13.8 and buffer volume 829\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0356\n",
            "Episode 87/20000(0.43%) finished with avg reward 7.2 w/ benchmark reward 13.8 and buffer volume 838\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0345\n",
            "Episode 88/20000(0.44%) finished with avg reward 7.2 w/ benchmark reward 13.8 and buffer volume 847\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1349\n",
            "Episode 89/20000(0.45%) finished with avg reward 6.9 w/ benchmark reward 13.8 and buffer volume 856\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0311\n",
            "Episode 90/20000(0.45%) finished with avg reward 7.6 w/ benchmark reward 13.8 and buffer volume 864\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1379\n",
            "Episode 91/20000(0.46%) finished with avg reward 6.9 w/ benchmark reward 13.8 and buffer volume 874\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1300\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Episode 92/20000(0.46%) finished with avg reward 8.9 w/ benchmark reward 13.8 and buffer volume 882\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2181\n",
            "Episode 93/20000(0.46%) finished with avg reward 7.6 w/ benchmark reward 13.8 and buffer volume 904\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2573\n",
            "Episode 94/20000(0.47%) finished with avg reward 7.1 w/ benchmark reward 13.8 and buffer volume 913\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2215\n",
            "Episode 95/20000(0.47%) finished with avg reward 7.0 w/ benchmark reward 13.8 and buffer volume 923\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0523\n",
            "Episode 96/20000(0.48%) finished with avg reward 7.3 w/ benchmark reward 13.8 and buffer volume 933\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2006\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Episode 97/20000(0.48%) finished with avg reward 10.4 w/ benchmark reward 13.8 and buffer volume 943\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1475\n",
            "Episode 98/20000(0.49%) finished with avg reward 7.1 w/ benchmark reward 13.8 and buffer volume 951\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2529\n",
            "Episode 99/20000(0.5%) finished with avg reward 7.6 w/ benchmark reward 13.8 and buffer volume 960\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0967\n",
            "Episode 100/20000(0.5%) finished with avg reward 9.0 w/ benchmark reward 13.8 and buffer volume 969\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1484\n",
            "Episode 101/20000(0.51%) finished with avg reward 8.6 w/ benchmark reward 13.8 and buffer volume 977\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0301\n",
            "Episode 102/20000(0.51%) finished with avg reward 7.0 w/ benchmark reward 13.8 and buffer volume 987\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1688\n",
            "Episode 103/20000(0.52%) finished with avg reward 7.8 w/ benchmark reward 13.8 and buffer volume 997\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0503\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Episode 104/20000(0.52%) finished with avg reward 13.5 w/ benchmark reward 13.8 and buffer volume 1005\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1484\n",
            "Episode 105/20000(0.53%) finished with avg reward 12.2 w/ benchmark reward 13.8 and buffer volume 1015\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0914\n",
            "Episode 106/20000(0.53%) finished with avg reward 9.1 w/ benchmark reward 13.8 and buffer volume 1024\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1872\n",
            "Episode 107/20000(0.53%) finished with avg reward 12.0 w/ benchmark reward 13.8 and buffer volume 1045\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0389\n",
            "Episode 108/20000(0.54%) finished with avg reward 11.4 w/ benchmark reward 13.8 and buffer volume 1054\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1709\n",
            "Episode 109/20000(0.55%) finished with avg reward 7.2 w/ benchmark reward 13.8 and buffer volume 1064\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2588\n",
            "Episode 110/20000(0.55%) finished with avg reward 12.3 w/ benchmark reward 13.8 and buffer volume 1074\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1936\n",
            "Episode 111/20000(0.56%) finished with avg reward 10.8 w/ benchmark reward 13.8 and buffer volume 1083\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2026\n",
            "Episode 112/20000(0.56%) finished with avg reward 11.3 w/ benchmark reward 13.8 and buffer volume 1093\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1157\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Episode 113/20000(0.56%) finished with avg reward 16.7 w/ benchmark reward 13.8 and buffer volume 1104\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0369\n",
            "Episode 114/20000(0.57%) finished with avg reward 11.5 w/ benchmark reward 13.8 and buffer volume 1113\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2675\n",
            "Episode 115/20000(0.57%) finished with avg reward 12.2 w/ benchmark reward 13.8 and buffer volume 1122\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1144\n",
            "Episode 116/20000(0.58%) finished with avg reward 14.7 w/ benchmark reward 13.8 and buffer volume 1142\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2476\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Episode 117/20000(0.58%) finished with avg reward 22.1 w/ benchmark reward 13.8 and buffer volume 1151\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1944\n",
            "Episode 118/20000(0.59%) finished with avg reward 16.2 w/ benchmark reward 13.8 and buffer volume 1162\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.3044\n",
            "Episode 119/20000(0.6%) finished with avg reward 13.9 w/ benchmark reward 13.8 and buffer volume 1171\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2153\n",
            "Episode 120/20000(0.6%) finished with avg reward 17.2 w/ benchmark reward 13.8 and buffer volume 1216\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1672\n",
            "Episode 121/20000(0.6%) finished with avg reward 17.4 w/ benchmark reward 13.8 and buffer volume 1251\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2920\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Episode 122/20000(0.61%) finished with avg reward 25.2 w/ benchmark reward 13.8 and buffer volume 1261\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1816\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Episode 123/20000(0.61%) finished with avg reward 34.8 w/ benchmark reward 13.8 and buffer volume 1278\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1628\n",
            "Episode 124/20000(0.62%) finished with avg reward 26.3 w/ benchmark reward 13.8 and buffer volume 1308\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1487\n",
            "Episode 125/20000(0.62%) finished with avg reward 31.3 w/ benchmark reward 13.8 and buffer volume 1349\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.3489\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Episode 126/20000(0.63%) finished with avg reward 37.0 w/ benchmark reward 13.8 and buffer volume 1373\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.3492\n",
            "Episode 127/20000(0.64%) finished with avg reward 33.6 w/ benchmark reward 13.8 and buffer volume 1412\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2369\n",
            "Episode 128/20000(0.64%) finished with avg reward 34.6 w/ benchmark reward 13.8 and buffer volume 1450\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.4268\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Episode 129/20000(0.65%) finished with avg reward 41.1 w/ benchmark reward 13.8 and buffer volume 1497\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.3105\n",
            "Episode 130/20000(0.65%) finished with avg reward 35.7 w/ benchmark reward 13.8 and buffer volume 1525\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.3229\n",
            "Episode 131/20000(0.66%) finished with avg reward 39.8 w/ benchmark reward 13.8 and buffer volume 1551\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.4832\n",
            "Episode 132/20000(0.66%) finished with avg reward 31.6 w/ benchmark reward 13.8 and buffer volume 1586\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2495\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Episode 133/20000(0.66%) finished with avg reward 46.4 w/ benchmark reward 13.8 and buffer volume 1634\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.4104\n",
            "Episode 134/20000(0.67%) finished with avg reward 40.7 w/ benchmark reward 13.8 and buffer volume 1677\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.3166\n",
            "Episode 135/20000(0.68%) finished with avg reward 40.7 w/ benchmark reward 13.8 and buffer volume 1724\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2876\n",
            "Episode 136/20000(0.68%) finished with avg reward 40.3 w/ benchmark reward 13.8 and buffer volume 1762\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1785\n",
            "Episode 137/20000(0.69%) finished with avg reward 38.7 w/ benchmark reward 13.8 and buffer volume 1800\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2161\n",
            "Episode 138/20000(0.69%) finished with avg reward 44.6 w/ benchmark reward 13.8 and buffer volume 1831\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.3345\n",
            "Episode 139/20000(0.69%) finished with avg reward 38.8 w/ benchmark reward 13.8 and buffer volume 1889\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1010\n",
            "Episode 140/20000(0.7%) finished with avg reward 41.0 w/ benchmark reward 13.8 and buffer volume 1922\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1861\n",
            "Episode 141/20000(0.7%) finished with avg reward 43.5 w/ benchmark reward 13.8 and buffer volume 1973\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1869\n",
            "Episode 142/20000(0.71%) finished with avg reward 36.2 w/ benchmark reward 13.8 and buffer volume 2014\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1126\n",
            "Episode 143/20000(0.71%) finished with avg reward 37.6 w/ benchmark reward 13.8 and buffer volume 2046\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1347\n",
            "Episode 144/20000(0.72%) finished with avg reward 32.8 w/ benchmark reward 13.8 and buffer volume 2077\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1705\n",
            "Episode 145/20000(0.73%) finished with avg reward 36.9 w/ benchmark reward 13.8 and buffer volume 2113\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2584\n",
            "Episode 146/20000(0.73%) finished with avg reward 39.7 w/ benchmark reward 13.8 and buffer volume 2145\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1226\n",
            "Episode 147/20000(0.73%) finished with avg reward 36.7 w/ benchmark reward 13.8 and buffer volume 2183\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2002\n",
            "Episode 148/20000(0.74%) finished with avg reward 38.9 w/ benchmark reward 13.8 and buffer volume 2226\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1218\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Episode 149/20000(0.74%) finished with avg reward 47.5 w/ benchmark reward 13.8 and buffer volume 2271\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1632\n",
            "Episode 150/20000(0.75%) finished with avg reward 37.9 w/ benchmark reward 13.8 and buffer volume 2324\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1210\n",
            "Episode 151/20000(0.76%) finished with avg reward 40.8 w/ benchmark reward 13.8 and buffer volume 2356\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1230\n",
            "Episode 152/20000(0.76%) finished with avg reward 38.2 w/ benchmark reward 13.8 and buffer volume 2410\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0852\n",
            "Episode 153/20000(0.77%) finished with avg reward 41.3 w/ benchmark reward 13.8 and buffer volume 2445\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1354\n",
            "Episode 154/20000(0.77%) finished with avg reward 40.7 w/ benchmark reward 13.8 and buffer volume 2484\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1138\n",
            "Episode 155/20000(0.78%) finished with avg reward 41.7 w/ benchmark reward 13.8 and buffer volume 2522\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0892\n",
            "Episode 156/20000(0.78%) finished with avg reward 44.5 w/ benchmark reward 13.8 and buffer volume 2567\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1029\n",
            "Episode 157/20000(0.78%) finished with avg reward 40.4 w/ benchmark reward 13.8 and buffer volume 2626\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1346\n",
            "Episode 158/20000(0.79%) finished with avg reward 46.4 w/ benchmark reward 13.8 and buffer volume 2685\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1243\n",
            "Episode 159/20000(0.8%) finished with avg reward 43.4 w/ benchmark reward 13.8 and buffer volume 2728\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1522\n",
            "Episode 160/20000(0.8%) finished with avg reward 40.4 w/ benchmark reward 13.8 and buffer volume 2775\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1302\n",
            "Episode 161/20000(0.8%) finished with avg reward 45.5 w/ benchmark reward 13.8 and buffer volume 2816\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1296\n",
            "Episode 162/20000(0.81%) finished with avg reward 44.8 w/ benchmark reward 13.8 and buffer volume 2856\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1215\n",
            "Episode 163/20000(0.81%) finished with avg reward 45.0 w/ benchmark reward 13.8 and buffer volume 2911\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1210\n",
            "Episode 164/20000(0.82%) finished with avg reward 36.5 w/ benchmark reward 13.8 and buffer volume 2962\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1540\n",
            "Episode 165/20000(0.83%) finished with avg reward 41.7 w/ benchmark reward 13.8 and buffer volume 2995\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2889\n",
            "Episode 166/20000(0.83%) finished with avg reward 46.4 w/ benchmark reward 13.8 and buffer volume 3033\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1748\n",
            "Episode 167/20000(0.83%) finished with avg reward 43.3 w/ benchmark reward 13.8 and buffer volume 3101\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1673\n",
            "Episode 168/20000(0.84%) finished with avg reward 42.8 w/ benchmark reward 13.8 and buffer volume 3170\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2083\n",
            "Episode 169/20000(0.84%) finished with avg reward 44.9 w/ benchmark reward 13.8 and buffer volume 3205\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1645\n",
            "Episode 170/20000(0.85%) finished with avg reward 40.5 w/ benchmark reward 13.8 and buffer volume 3244\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1517\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Episode 171/20000(0.85%) finished with avg reward 49.1 w/ benchmark reward 13.8 and buffer volume 3290\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2732\n",
            "Episode 172/20000(0.86%) finished with avg reward 45.7 w/ benchmark reward 13.8 and buffer volume 3329\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1955\n",
            "Episode 173/20000(0.86%) finished with avg reward 45.9 w/ benchmark reward 13.8 and buffer volume 3376\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2318\n",
            "Episode 174/20000(0.87%) finished with avg reward 40.7 w/ benchmark reward 13.8 and buffer volume 3421\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1672\n",
            "Episode 175/20000(0.88%) finished with avg reward 48.2 w/ benchmark reward 13.8 and buffer volume 3453\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1509\n",
            "Episode 176/20000(0.88%) finished with avg reward 41.4 w/ benchmark reward 13.8 and buffer volume 3488\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1143\n",
            "Episode 177/20000(0.89%) finished with avg reward 43.1 w/ benchmark reward 13.8 and buffer volume 3523\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0827\n",
            "Episode 178/20000(0.89%) finished with avg reward 42.2 w/ benchmark reward 13.8 and buffer volume 3577\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1094\n",
            "Episode 179/20000(0.9%) finished with avg reward 38.2 w/ benchmark reward 13.8 and buffer volume 3613\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0897\n",
            "Episode 180/20000(0.9%) finished with avg reward 45.1 w/ benchmark reward 13.8 and buffer volume 3670\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0884\n",
            "Episode 181/20000(0.91%) finished with avg reward 38.1 w/ benchmark reward 13.8 and buffer volume 3728\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1181\n",
            "Episode 182/20000(0.91%) finished with avg reward 46.0 w/ benchmark reward 13.8 and buffer volume 3788\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1058\n",
            "Episode 183/20000(0.92%) finished with avg reward 45.3 w/ benchmark reward 13.8 and buffer volume 3841\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1048\n",
            "Episode 184/20000(0.92%) finished with avg reward 46.4 w/ benchmark reward 13.8 and buffer volume 3901\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1113\n",
            "Episode 185/20000(0.92%) finished with avg reward 40.4 w/ benchmark reward 13.8 and buffer volume 3966\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0436\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Episode 186/20000(0.93%) finished with avg reward 54.0 w/ benchmark reward 13.8 and buffer volume 3999\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0681\n",
            "Episode 187/20000(0.94%) finished with avg reward 40.9 w/ benchmark reward 13.8 and buffer volume 4040\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1315\n",
            "Episode 188/20000(0.94%) finished with avg reward 46.1 w/ benchmark reward 13.8 and buffer volume 4095\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0938\n",
            "Episode 189/20000(0.95%) finished with avg reward 42.9 w/ benchmark reward 13.8 and buffer volume 4130\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0652\n",
            "Episode 190/20000(0.95%) finished with avg reward 44.5 w/ benchmark reward 13.8 and buffer volume 4195\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0711\n",
            "Episode 191/20000(0.95%) finished with avg reward 41.2 w/ benchmark reward 13.8 and buffer volume 4227\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0836\n",
            "Episode 192/20000(0.96%) finished with avg reward 44.8 w/ benchmark reward 13.8 and buffer volume 4289\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0788\n",
            "Episode 193/20000(0.97%) finished with avg reward 39.6 w/ benchmark reward 13.8 and buffer volume 4329\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0770\n",
            "Episode 194/20000(0.97%) finished with avg reward 46.7 w/ benchmark reward 13.8 and buffer volume 4365\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1018\n",
            "Episode 195/20000(0.97%) finished with avg reward 49.5 w/ benchmark reward 13.8 and buffer volume 4397\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1469\n",
            "Episode 196/20000(0.98%) finished with avg reward 47.8 w/ benchmark reward 13.8 and buffer volume 4445\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0857\n",
            "Episode 197/20000(0.98%) finished with avg reward 45.3 w/ benchmark reward 13.8 and buffer volume 4489\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0956\n",
            "Episode 198/20000(0.99%) finished with avg reward 45.7 w/ benchmark reward 13.8 and buffer volume 4532\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1096\n",
            "Episode 199/20000(1.0%) finished with avg reward 41.3 w/ benchmark reward 13.8 and buffer volume 4576\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0847\n",
            "Episode 200/20000(1.0%) finished with avg reward 41.0 w/ benchmark reward 13.8 and buffer volume 4616\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0567\n",
            "Episode 201/20000(1.0%) finished with avg reward 44.7 w/ benchmark reward 13.8 and buffer volume 4658\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0928\n",
            "Episode 202/20000(1.01%) finished with avg reward 43.8 w/ benchmark reward 13.8 and buffer volume 4693\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1180\n",
            "Episode 203/20000(1.01%) finished with avg reward 48.1 w/ benchmark reward 13.8 and buffer volume 4741\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1281\n",
            "Episode 204/20000(1.02%) finished with avg reward 44.1 w/ benchmark reward 13.8 and buffer volume 4796\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0770\n",
            "Episode 205/20000(1.03%) finished with avg reward 39.2 w/ benchmark reward 13.8 and buffer volume 4830\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0686\n",
            "Episode 206/20000(1.03%) finished with avg reward 39.8 w/ benchmark reward 13.8 and buffer volume 4864\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0703\n",
            "Episode 207/20000(1.03%) finished with avg reward 46.0 w/ benchmark reward 13.8 and buffer volume 4930\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0663\n",
            "Episode 208/20000(1.04%) finished with avg reward 49.0 w/ benchmark reward 13.8 and buffer volume 4982\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0915\n",
            "Episode 209/20000(1.04%) finished with avg reward 48.7 w/ benchmark reward 13.8 and buffer volume 5029\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0977\n",
            "Episode 210/20000(1.05%) finished with avg reward 53.2 w/ benchmark reward 13.8 and buffer volume 5088\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0624\n",
            "Episode 211/20000(1.05%) finished with avg reward 46.3 w/ benchmark reward 13.8 and buffer volume 5149\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0712\n",
            "Episode 212/20000(1.06%) finished with avg reward 43.5 w/ benchmark reward 13.8 and buffer volume 5207\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1371\n",
            "Episode 213/20000(1.06%) finished with avg reward 44.0 w/ benchmark reward 13.8 and buffer volume 5275\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1271\n",
            "Episode 214/20000(1.07%) finished with avg reward 47.4 w/ benchmark reward 13.8 and buffer volume 5323\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0466\n",
            "Episode 215/20000(1.07%) finished with avg reward 51.7 w/ benchmark reward 13.8 and buffer volume 5392\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0419\n",
            "Episode 216/20000(1.08%) finished with avg reward 48.3 w/ benchmark reward 13.8 and buffer volume 5468\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1815\n",
            "Episode 217/20000(1.08%) finished with avg reward 42.6 w/ benchmark reward 13.8 and buffer volume 5501\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1619\n",
            "Episode 218/20000(1.09%) finished with avg reward 46.8 w/ benchmark reward 13.8 and buffer volume 5542\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1539\n",
            "Episode 219/20000(1.09%) finished with avg reward 44.0 w/ benchmark reward 13.8 and buffer volume 5605\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1205\n",
            "Episode 220/20000(1.1%) finished with avg reward 45.7 w/ benchmark reward 13.8 and buffer volume 5642\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0578\n",
            "Episode 221/20000(1.1%) finished with avg reward 41.9 w/ benchmark reward 13.8 and buffer volume 5682\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0740\n",
            "Episode 222/20000(1.11%) finished with avg reward 43.9 w/ benchmark reward 13.8 and buffer volume 5741\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0884\n",
            "Episode 223/20000(1.11%) finished with avg reward 40.0 w/ benchmark reward 13.8 and buffer volume 5778\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1478\n",
            "Episode 224/20000(1.12%) finished with avg reward 49.9 w/ benchmark reward 13.8 and buffer volume 5820\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0531\n",
            "Episode 225/20000(1.12%) finished with avg reward 39.9 w/ benchmark reward 13.8 and buffer volume 5889\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0689\n",
            "Episode 226/20000(1.13%) finished with avg reward 47.0 w/ benchmark reward 13.8 and buffer volume 5924\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0983\n",
            "Episode 227/20000(1.14%) finished with avg reward 45.9 w/ benchmark reward 13.8 and buffer volume 5958\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1399\n",
            "Episode 228/20000(1.14%) finished with avg reward 48.4 w/ benchmark reward 13.8 and buffer volume 6014\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0526\n",
            "Episode 229/20000(1.15%) finished with avg reward 49.1 w/ benchmark reward 13.8 and buffer volume 6091\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1793\n",
            "Episode 230/20000(1.15%) finished with avg reward 51.5 w/ benchmark reward 13.8 and buffer volume 6146\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0632\n",
            "Episode 231/20000(1.16%) finished with avg reward 42.8 w/ benchmark reward 13.8 and buffer volume 6207\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0799\n",
            "Episode 232/20000(1.16%) finished with avg reward 48.4 w/ benchmark reward 13.8 and buffer volume 6242\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1587\n",
            "Episode 233/20000(1.17%) finished with avg reward 48.4 w/ benchmark reward 13.8 and buffer volume 6301\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0596\n",
            "Episode 234/20000(1.17%) finished with avg reward 43.0 w/ benchmark reward 13.8 and buffer volume 6338\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0995\n",
            "Episode 235/20000(1.18%) finished with avg reward 50.0 w/ benchmark reward 13.8 and buffer volume 6373\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0779\n",
            "Episode 236/20000(1.18%) finished with avg reward 45.6 w/ benchmark reward 13.8 and buffer volume 6436\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0690\n",
            "Episode 237/20000(1.19%) finished with avg reward 39.8 w/ benchmark reward 13.8 and buffer volume 6493\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0637\n",
            "Episode 238/20000(1.19%) finished with avg reward 48.3 w/ benchmark reward 13.8 and buffer volume 6530\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0499\n",
            "Episode 239/20000(1.2%) finished with avg reward 48.4 w/ benchmark reward 13.8 and buffer volume 6565\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0817\n",
            "Episode 240/20000(1.2%) finished with avg reward 51.2 w/ benchmark reward 13.8 and buffer volume 6612\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0909\n",
            "Episode 241/20000(1.21%) finished with avg reward 46.6 w/ benchmark reward 13.8 and buffer volume 6667\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0382\n",
            "Episode 242/20000(1.21%) finished with avg reward 44.9 w/ benchmark reward 13.8 and buffer volume 6727\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0509\n",
            "Episode 243/20000(1.21%) finished with avg reward 50.7 w/ benchmark reward 13.8 and buffer volume 6790\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0604\n",
            "Episode 244/20000(1.22%) finished with avg reward 44.8 w/ benchmark reward 13.8 and buffer volume 6835\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0753\n",
            "Episode 245/20000(1.23%) finished with avg reward 40.7 w/ benchmark reward 13.8 and buffer volume 6890\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1083\n",
            "Episode 246/20000(1.23%) finished with avg reward 41.4 w/ benchmark reward 13.8 and buffer volume 6938\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0288\n",
            "Episode 247/20000(1.23%) finished with avg reward 41.9 w/ benchmark reward 13.8 and buffer volume 7006\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0866\n",
            "Episode 248/20000(1.24%) finished with avg reward 46.0 w/ benchmark reward 13.8 and buffer volume 7041\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0743\n",
            "Episode 249/20000(1.24%) finished with avg reward 41.5 w/ benchmark reward 13.8 and buffer volume 7097\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0529\n",
            "Episode 250/20000(1.25%) finished with avg reward 41.5 w/ benchmark reward 13.8 and buffer volume 7144\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0305\n",
            "Episode 251/20000(1.26%) finished with avg reward 48.4 w/ benchmark reward 13.8 and buffer volume 7185\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0703\n",
            "Episode 252/20000(1.26%) finished with avg reward 39.9 w/ benchmark reward 13.8 and buffer volume 7249\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0424\n",
            "Episode 253/20000(1.26%) finished with avg reward 50.3 w/ benchmark reward 13.8 and buffer volume 7312\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1488\n",
            "Episode 254/20000(1.27%) finished with avg reward 46.6 w/ benchmark reward 13.8 and buffer volume 7355\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0598\n",
            "Episode 255/20000(1.27%) finished with avg reward 51.6 w/ benchmark reward 13.8 and buffer volume 7414\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0445\n",
            "Episode 256/20000(1.28%) finished with avg reward 47.2 w/ benchmark reward 13.8 and buffer volume 7457\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1638\n",
            "Episode 257/20000(1.29%) finished with avg reward 43.5 w/ benchmark reward 13.8 and buffer volume 7514\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0846\n",
            "Episode 258/20000(1.29%) finished with avg reward 41.7 w/ benchmark reward 13.8 and buffer volume 7558\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0331\n",
            "Episode 259/20000(1.29%) finished with avg reward 45.1 w/ benchmark reward 13.8 and buffer volume 7605\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1155\n",
            "Episode 260/20000(1.3%) finished with avg reward 42.1 w/ benchmark reward 13.8 and buffer volume 7652\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0441\n",
            "Episode 261/20000(1.31%) finished with avg reward 44.8 w/ benchmark reward 13.8 and buffer volume 7719\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Episode 262/20000(1.31%) finished with avg reward 53.4 w/ benchmark reward 13.8 and buffer volume 7763\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1056\n",
            "Episode 263/20000(1.31%) finished with avg reward 50.1 w/ benchmark reward 13.8 and buffer volume 7804\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0755\n",
            "Episode 264/20000(1.32%) finished with avg reward 42.0 w/ benchmark reward 13.8 and buffer volume 7847\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0461\n",
            "Episode 265/20000(1.32%) finished with avg reward 50.4 w/ benchmark reward 13.8 and buffer volume 7892\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0930\n",
            "Episode 266/20000(1.33%) finished with avg reward 46.8 w/ benchmark reward 13.8 and buffer volume 7933\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0454\n",
            "Episode 267/20000(1.33%) finished with avg reward 45.3 w/ benchmark reward 13.8 and buffer volume 8012\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0829\n",
            "Episode 268/20000(1.34%) finished with avg reward 48.9 w/ benchmark reward 13.8 and buffer volume 8047\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0941\n",
            "Episode 269/20000(1.34%) finished with avg reward 38.7 w/ benchmark reward 13.8 and buffer volume 8116\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0553\n",
            "Episode 270/20000(1.35%) finished with avg reward 44.5 w/ benchmark reward 13.8 and buffer volume 8151\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1050\n",
            "Episode 271/20000(1.35%) finished with avg reward 38.3 w/ benchmark reward 13.8 and buffer volume 8188\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1302\n",
            "Episode 272/20000(1.36%) finished with avg reward 44.6 w/ benchmark reward 13.8 and buffer volume 8255\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0344\n",
            "Episode 273/20000(1.36%) finished with avg reward 47.3 w/ benchmark reward 13.8 and buffer volume 8292\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0379\n",
            "Episode 274/20000(1.37%) finished with avg reward 48.7 w/ benchmark reward 13.8 and buffer volume 8348\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0334\n",
            "Episode 275/20000(1.38%) finished with avg reward 39.2 w/ benchmark reward 13.8 and buffer volume 8403\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0694\n",
            "Episode 276/20000(1.38%) finished with avg reward 51.3 w/ benchmark reward 13.8 and buffer volume 8442\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0855\n",
            "Episode 277/20000(1.39%) finished with avg reward 41.8 w/ benchmark reward 13.8 and buffer volume 8475\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0635\n",
            "Episode 278/20000(1.39%) finished with avg reward 42.7 w/ benchmark reward 13.8 and buffer volume 8520\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1273\n",
            "Episode 279/20000(1.4%) finished with avg reward 42.9 w/ benchmark reward 13.8 and buffer volume 8585\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0813\n",
            "Episode 280/20000(1.4%) finished with avg reward 38.4 w/ benchmark reward 13.8 and buffer volume 8624\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0363\n",
            "Episode 281/20000(1.41%) finished with avg reward 49.5 w/ benchmark reward 13.8 and buffer volume 8660\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0433\n",
            "Episode 282/20000(1.41%) finished with avg reward 41.1 w/ benchmark reward 13.8 and buffer volume 8709\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0657\n",
            "Episode 283/20000(1.42%) finished with avg reward 49.3 w/ benchmark reward 13.8 and buffer volume 8748\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1093\n",
            "Episode 284/20000(1.42%) finished with avg reward 45.4 w/ benchmark reward 13.8 and buffer volume 8837\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0489\n",
            "Episode 285/20000(1.43%) finished with avg reward 45.9 w/ benchmark reward 13.8 and buffer volume 8873\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0685\n",
            "Episode 286/20000(1.43%) finished with avg reward 45.0 w/ benchmark reward 13.8 and buffer volume 8937\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0515\n",
            "Episode 287/20000(1.44%) finished with avg reward 48.5 w/ benchmark reward 13.8 and buffer volume 8972\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0998\n",
            "Episode 288/20000(1.44%) finished with avg reward 49.5 w/ benchmark reward 13.8 and buffer volume 9007\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0706\n",
            "Episode 289/20000(1.44%) finished with avg reward 40.7 w/ benchmark reward 13.8 and buffer volume 9050\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0581\n",
            "Episode 290/20000(1.45%) finished with avg reward 47.7 w/ benchmark reward 13.8 and buffer volume 9111\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0512\n",
            "Episode 291/20000(1.46%) finished with avg reward 46.0 w/ benchmark reward 13.8 and buffer volume 9144\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0940\n",
            "Episode 292/20000(1.46%) finished with avg reward 49.3 w/ benchmark reward 13.8 and buffer volume 9187\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0710\n",
            "Episode 293/20000(1.47%) finished with avg reward 39.8 w/ benchmark reward 13.8 and buffer volume 9236\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0229\n",
            "Episode 294/20000(1.47%) finished with avg reward 50.2 w/ benchmark reward 13.8 and buffer volume 9275\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0463\n",
            "Episode 295/20000(1.47%) finished with avg reward 40.9 w/ benchmark reward 13.8 and buffer volume 9320\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1190\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Episode 296/20000(1.48%) finished with avg reward 58.5 w/ benchmark reward 13.8 and buffer volume 9363\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0461\n",
            "Episode 297/20000(1.49%) finished with avg reward 43.5 w/ benchmark reward 13.8 and buffer volume 9415\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0598\n",
            "Episode 298/20000(1.49%) finished with avg reward 47.0 w/ benchmark reward 13.8 and buffer volume 9476\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0783\n",
            "Episode 299/20000(1.49%) finished with avg reward 50.1 w/ benchmark reward 13.8 and buffer volume 9538\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0755\n",
            "Episode 300/20000(1.5%) finished with avg reward 47.5 w/ benchmark reward 13.8 and buffer volume 9621\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0710\n",
            "Episode 301/20000(1.5%) finished with avg reward 46.1 w/ benchmark reward 13.8 and buffer volume 9668\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0124\n",
            "Episode 302/20000(1.51%) finished with avg reward 49.4 w/ benchmark reward 13.8 and buffer volume 9741\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0532\n",
            "Episode 303/20000(1.52%) finished with avg reward 42.3 w/ benchmark reward 13.8 and buffer volume 9812\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0390\n",
            "Episode 304/20000(1.52%) finished with avg reward 38.9 w/ benchmark reward 13.8 and buffer volume 9861\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Episode 305/20000(1.52%) finished with avg reward 46.4 w/ benchmark reward 13.8 and buffer volume 9904\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0700\n",
            "Episode 306/20000(1.53%) finished with avg reward 55.5 w/ benchmark reward 13.8 and buffer volume 9943\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0475\n",
            "Episode 307/20000(1.54%) finished with avg reward 43.0 w/ benchmark reward 13.8 and buffer volume 10000\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0603\n",
            "Episode 308/20000(1.54%) finished with avg reward 55.9 w/ benchmark reward 13.8 and buffer volume 10041\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0505\n",
            "Episode 309/20000(1.54%) finished with avg reward 44.4 w/ benchmark reward 13.8 and buffer volume 10094\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0518\n",
            "Episode 310/20000(1.55%) finished with avg reward 48.1 w/ benchmark reward 13.8 and buffer volume 10177\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0173\n",
            "Episode 311/20000(1.55%) finished with avg reward 51.7 w/ benchmark reward 13.8 and buffer volume 10212\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0205\n",
            "Episode 312/20000(1.56%) finished with avg reward 53.8 w/ benchmark reward 13.8 and buffer volume 10259\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0172\n",
            "Episode 313/20000(1.57%) finished with avg reward 46.5 w/ benchmark reward 13.8 and buffer volume 10297\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1520\n",
            "Episode 314/20000(1.57%) finished with avg reward 41.3 w/ benchmark reward 13.8 and buffer volume 10337\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1086\n",
            "Episode 315/20000(1.57%) finished with avg reward 49.6 w/ benchmark reward 13.8 and buffer volume 10382\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0573\n",
            "Episode 316/20000(1.58%) finished with avg reward 48.9 w/ benchmark reward 13.8 and buffer volume 10418\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1046\n",
            "Episode 317/20000(1.58%) finished with avg reward 48.0 w/ benchmark reward 13.8 and buffer volume 10465\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0391\n",
            "Episode 318/20000(1.59%) finished with avg reward 58.3 w/ benchmark reward 13.8 and buffer volume 10528\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0177\n",
            "Episode 319/20000(1.59%) finished with avg reward 51.8 w/ benchmark reward 13.8 and buffer volume 10565\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0410\n",
            "Episode 320/20000(1.6%) finished with avg reward 42.8 w/ benchmark reward 13.8 and buffer volume 10605\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0493\n",
            "Episode 321/20000(1.6%) finished with avg reward 51.2 w/ benchmark reward 13.8 and buffer volume 10696\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0746\n",
            "Episode 322/20000(1.61%) finished with avg reward 57.8 w/ benchmark reward 13.8 and buffer volume 10731\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0357\n",
            "Episode 323/20000(1.62%) finished with avg reward 56.1 w/ benchmark reward 13.8 and buffer volume 10792\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0161\n",
            "Episode 324/20000(1.62%) finished with avg reward 50.7 w/ benchmark reward 13.8 and buffer volume 10831\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0294\n",
            "Episode 325/20000(1.62%) finished with avg reward 51.0 w/ benchmark reward 13.8 and buffer volume 10892\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0516\n",
            "Episode 326/20000(1.63%) finished with avg reward 50.2 w/ benchmark reward 13.8 and buffer volume 10977\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0385\n",
            "Episode 327/20000(1.64%) finished with avg reward 52.4 w/ benchmark reward 13.8 and buffer volume 11036\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0538\n",
            "Episode 328/20000(1.64%) finished with avg reward 48.9 w/ benchmark reward 13.8 and buffer volume 11109\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0345\n",
            "Episode 329/20000(1.65%) finished with avg reward 50.6 w/ benchmark reward 13.8 and buffer volume 11166\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0435\n",
            "Episode 330/20000(1.65%) finished with avg reward 50.3 w/ benchmark reward 13.8 and buffer volume 11235\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0689\n",
            "Episode 331/20000(1.65%) finished with avg reward 48.7 w/ benchmark reward 13.8 and buffer volume 11291\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0656\n",
            "Episode 332/20000(1.66%) finished with avg reward 52.2 w/ benchmark reward 13.8 and buffer volume 11357\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0624\n",
            "Episode 333/20000(1.67%) finished with avg reward 45.6 w/ benchmark reward 13.8 and buffer volume 11399\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0373\n",
            "Episode 334/20000(1.67%) finished with avg reward 39.0 w/ benchmark reward 13.8 and buffer volume 11464\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0377\n",
            "Episode 335/20000(1.68%) finished with avg reward 45.4 w/ benchmark reward 13.8 and buffer volume 11517\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0165\n",
            "Episode 336/20000(1.68%) finished with avg reward 51.4 w/ benchmark reward 13.8 and buffer volume 11556\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0394\n",
            "Episode 337/20000(1.69%) finished with avg reward 44.9 w/ benchmark reward 13.8 and buffer volume 11595\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0363\n",
            "Episode 338/20000(1.69%) finished with avg reward 45.4 w/ benchmark reward 13.8 and buffer volume 11682\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1084\n",
            "Episode 339/20000(1.7%) finished with avg reward 54.8 w/ benchmark reward 13.8 and buffer volume 11725\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0275\n",
            "Episode 340/20000(1.7%) finished with avg reward 40.3 w/ benchmark reward 13.8 and buffer volume 11768\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0268\n",
            "Episode 341/20000(1.7%) finished with avg reward 57.1 w/ benchmark reward 13.8 and buffer volume 11815\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0539\n",
            "Episode 342/20000(1.71%) finished with avg reward 53.4 w/ benchmark reward 13.8 and buffer volume 11890\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0554\n",
            "Episode 343/20000(1.71%) finished with avg reward 50.9 w/ benchmark reward 13.8 and buffer volume 11933\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0241\n",
            "Episode 344/20000(1.72%) finished with avg reward 50.1 w/ benchmark reward 13.8 and buffer volume 11970\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0155\n",
            "Episode 345/20000(1.73%) finished with avg reward 51.7 w/ benchmark reward 13.8 and buffer volume 12011\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0942\n",
            "Episode 346/20000(1.73%) finished with avg reward 55.9 w/ benchmark reward 13.8 and buffer volume 12068\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0555\n",
            "Episode 347/20000(1.74%) finished with avg reward 58.2 w/ benchmark reward 13.8 and buffer volume 12113\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0224\n",
            "Episode 348/20000(1.74%) finished with avg reward 43.4 w/ benchmark reward 13.8 and buffer volume 12152\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0480\n",
            "Episode 349/20000(1.75%) finished with avg reward 46.8 w/ benchmark reward 13.8 and buffer volume 12197\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0816\n",
            "Episode 350/20000(1.75%) finished with avg reward 54.0 w/ benchmark reward 13.8 and buffer volume 12263\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0587\n",
            "Episode 351/20000(1.75%) finished with avg reward 44.5 w/ benchmark reward 13.8 and buffer volume 12342\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0254\n",
            "Episode 352/20000(1.76%) finished with avg reward 50.4 w/ benchmark reward 13.8 and buffer volume 12387\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0198\n",
            "Episode 353/20000(1.76%) finished with avg reward 53.0 w/ benchmark reward 13.8 and buffer volume 12474\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0467\n",
            "Episode 354/20000(1.77%) finished with avg reward 52.9 w/ benchmark reward 13.8 and buffer volume 12511\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0757\n",
            "Episode 355/20000(1.77%) finished with avg reward 46.4 w/ benchmark reward 13.8 and buffer volume 12576\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0400\n",
            "Episode 356/20000(1.78%) finished with avg reward 56.5 w/ benchmark reward 13.8 and buffer volume 12639\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1344\n",
            "Episode 357/20000(1.79%) finished with avg reward 50.0 w/ benchmark reward 13.8 and buffer volume 12680\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0511\n",
            "Episode 358/20000(1.79%) finished with avg reward 54.6 w/ benchmark reward 13.8 and buffer volume 12720\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1389\n",
            "Episode 359/20000(1.8%) finished with avg reward 43.3 w/ benchmark reward 13.8 and buffer volume 12757\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0311\n",
            "Episode 360/20000(1.8%) finished with avg reward 51.5 w/ benchmark reward 13.8 and buffer volume 12800\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0295\n",
            "Episode 361/20000(1.8%) finished with avg reward 48.6 w/ benchmark reward 13.8 and buffer volume 12871\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1043\n",
            "Episode 362/20000(1.81%) finished with avg reward 50.9 w/ benchmark reward 13.8 and buffer volume 12923\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0658\n",
            "Episode 363/20000(1.81%) finished with avg reward 48.1 w/ benchmark reward 13.8 and buffer volume 12956\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0317\n",
            "Episode 364/20000(1.82%) finished with avg reward 44.1 w/ benchmark reward 13.8 and buffer volume 13022\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0630\n",
            "Episode 365/20000(1.82%) finished with avg reward 44.6 w/ benchmark reward 13.8 and buffer volume 13075\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0232\n",
            "Episode 366/20000(1.83%) finished with avg reward 44.2 w/ benchmark reward 13.8 and buffer volume 13131\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0145\n",
            "Episode 367/20000(1.84%) finished with avg reward 51.3 w/ benchmark reward 13.8 and buffer volume 13170\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0184\n",
            "Episode 368/20000(1.84%) finished with avg reward 53.4 w/ benchmark reward 13.8 and buffer volume 13205\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0636\n",
            "Episode 369/20000(1.85%) finished with avg reward 48.5 w/ benchmark reward 13.8 and buffer volume 13250\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0152\n",
            "Episode 370/20000(1.85%) finished with avg reward 45.6 w/ benchmark reward 13.8 and buffer volume 13307\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1124\n",
            "Episode 371/20000(1.85%) finished with avg reward 50.9 w/ benchmark reward 13.8 and buffer volume 13342\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0225\n",
            "Episode 372/20000(1.86%) finished with avg reward 48.2 w/ benchmark reward 13.8 and buffer volume 13389\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0213\n",
            "Episode 373/20000(1.86%) finished with avg reward 50.4 w/ benchmark reward 13.8 and buffer volume 13440\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0305\n",
            "Episode 374/20000(1.87%) finished with avg reward 46.9 w/ benchmark reward 13.8 and buffer volume 13477\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0631\n",
            "Episode 375/20000(1.88%) finished with avg reward 45.5 w/ benchmark reward 13.8 and buffer volume 13519\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0393\n",
            "Episode 376/20000(1.88%) finished with avg reward 49.4 w/ benchmark reward 13.8 and buffer volume 13558\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0548\n",
            "Episode 377/20000(1.88%) finished with avg reward 56.7 w/ benchmark reward 13.8 and buffer volume 13607\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0415\n",
            "Episode 378/20000(1.89%) finished with avg reward 51.0 w/ benchmark reward 13.8 and buffer volume 13646\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0675\n",
            "Episode 379/20000(1.9%) finished with avg reward 56.3 w/ benchmark reward 13.8 and buffer volume 13703\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0636\n",
            "Episode 380/20000(1.9%) finished with avg reward 57.5 w/ benchmark reward 13.8 and buffer volume 13765\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0877\n",
            "Episode 381/20000(1.91%) finished with avg reward 48.6 w/ benchmark reward 13.8 and buffer volume 13824\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0187\n",
            "Episode 382/20000(1.91%) finished with avg reward 46.4 w/ benchmark reward 13.8 and buffer volume 13882\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0490\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Episode 383/20000(1.92%) finished with avg reward 59.0 w/ benchmark reward 13.8 and buffer volume 13955\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0150\n",
            "Episode 384/20000(1.92%) finished with avg reward 49.4 w/ benchmark reward 13.8 and buffer volume 14011\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0853\n",
            "Episode 385/20000(1.93%) finished with avg reward 52.1 w/ benchmark reward 13.8 and buffer volume 14049\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0525\n",
            "Episode 386/20000(1.93%) finished with avg reward 54.9 w/ benchmark reward 13.8 and buffer volume 14114\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0936\n",
            "Episode 387/20000(1.93%) finished with avg reward 48.2 w/ benchmark reward 13.8 and buffer volume 14175\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0262\n",
            "Episode 388/20000(1.94%) finished with avg reward 50.1 w/ benchmark reward 13.8 and buffer volume 14237\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0630\n",
            "Episode 389/20000(1.94%) finished with avg reward 50.0 w/ benchmark reward 13.8 and buffer volume 14280\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0420\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n",
            "Episode 390/20000(1.95%) finished with avg reward 60.6 w/ benchmark reward 13.8 and buffer volume 14319\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0579\n",
            "Episode 391/20000(1.96%) finished with avg reward 47.3 w/ benchmark reward 13.8 and buffer volume 14363\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0310\n",
            "Episode 392/20000(1.96%) finished with avg reward 53.2 w/ benchmark reward 13.8 and buffer volume 14411\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0214\n",
            "Episode 393/20000(1.97%) finished with avg reward 47.2 w/ benchmark reward 13.8 and buffer volume 14448\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0360\n",
            "Episode 394/20000(1.97%) finished with avg reward 48.3 w/ benchmark reward 13.8 and buffer volume 14485\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0237\n",
            "Episode 395/20000(1.98%) finished with avg reward 45.3 w/ benchmark reward 13.8 and buffer volume 14560\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0226\n",
            "Episode 396/20000(1.98%) finished with avg reward 46.3 w/ benchmark reward 13.8 and buffer volume 14601\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0855\n",
            "Episode 397/20000(1.98%) finished with avg reward 52.5 w/ benchmark reward 13.8 and buffer volume 14666\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0734\n",
            "Episode 398/20000(1.99%) finished with avg reward 50.4 w/ benchmark reward 13.8 and buffer volume 14735\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0227\n",
            "Episode 399/20000(1.99%) finished with avg reward 48.5 w/ benchmark reward 13.8 and buffer volume 14786\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0472\n",
            "Episode 400/20000(2.0%) finished with avg reward 51.5 w/ benchmark reward 13.8 and buffer volume 14821\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0197\n",
            "Episode 401/20000(2.0%) finished with avg reward 53.3 w/ benchmark reward 13.8 and buffer volume 14918\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0204\n",
            "Episode 402/20000(2.01%) finished with avg reward 46.8 w/ benchmark reward 13.8 and buffer volume 14955\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0889\n",
            "Episode 403/20000(2.02%) finished with avg reward 50.0 w/ benchmark reward 13.8 and buffer volume 15033\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2923\n",
            "Episode 404/20000(2.02%) finished with avg reward 45.5 w/ benchmark reward 13.8 and buffer volume 15073\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0694\n",
            "Episode 405/20000(2.02%) finished with avg reward 59.2 w/ benchmark reward 13.8 and buffer volume 15117\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0347\n",
            "Episode 406/20000(2.03%) finished with avg reward 56.1 w/ benchmark reward 13.8 and buffer volume 15157\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0411\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylp1Y3wrCA9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}